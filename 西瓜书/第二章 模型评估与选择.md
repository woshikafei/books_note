## 模型评估方法
#### 留出法 hold-out
把样本分为两个互斥集合：训练集和测试集。包括分层采样（stratified sampling）。常见2/3或者4/5作为训练集。

#### 交叉验证法 cross validation
划分为k个大小相似的互斥子集（分层采样），每次取k-1个作为训练集，1个作为测试集，取k次。常见k=10或5.

#### 自助法 bootstrapping
以自助采样法bootstrap sampling为基础（bagging 有放回采样），（而pasting则为无放回采样）。初试数据集D中约有36.8%的样本未出现在采样数据集D'中，于是以D'作训练集，D\D'为测试集，这样有约1/3的未训练数据用于测试，亦称“包外估计”（out-of-bag estimate）。

它的优点是能生成多份不同训练集，对集成学习有好处，但是它改变了初始数据集的分布，会引入估计偏差。因此数据量足够时，交叉验证法更好。

## 性能度量
### 查准率precision、查全率recall、F1 score

*真实情况* | 预测为正例 | 预测为反例
---|---|---
**正例** | TP | FN
**反例** | FP | TN

查准率：$ P = \frac{TP}{TP+FP}$

查全率：$ R = \frac{TP}{TP+FN}$

平衡点 BEP：P=R时的取值

$$
F1 = \frac{2*P*R}{P+R} = \frac{2*TP}{\text{样例总数}+TP-TN} \\

F_{\beta} = \frac{(1+\beta ^2)*P*R}{(\beta ^2 * P)+R}
$$

### ROC与AUC
真正例率： $ TPR=\frac{TP}{TP+FN} $

假正例率： $ TPR=\frac{FP}{TN+FP} $

ROC图：把每个样本预测到的概率作为key进行排序，最后按每一个key作为阈值进行划分，然后以`TPR`作为纵坐标，`FPR`作为横坐标作图。

AUC：ROC图中曲线向下围成的面积。
$$
AUC = \frac{1}{2} = \frac{1}{2} \sum^{m-1}_{i=1}(x_{i+1}-x_i)\cdot(y_i+y_{i+1})
$$

### 代价敏感错误率
$$
cost_{norm} = \frac{FNR*p*cost_{01}+FPR*(1-p)*cost_{10}}{p*cost_{01}+(1-p)*cost_{10}}
$$
,其中p是样例为正的概率,$cost_{01}$是真实为0，预测为1情况下的损失值（自己选择值的大小）。

## 比较检验
### 交叉验证t检验
对“学习器A与B性能相同”这个假设做t检验，先对每对结果求差，计算出均值$\mu$和方差$\sigma^2$，在显著度$\alpha$下，若变量
$\tau_t=\vert \frac{\sqrt{k}\mu}{\sigma} \vert$
小于临界值$t_{\alpha/2,k-1}$，则假设不能拒绝，性能没有显著差别。
可以选用5*2折交叉验证，平均值$\mu$只计算第一次2折上的平均值，而对每次2折都计算出方差。
$$
\tau_t = \frac{\mu}{\sqrt{0.2\sum^5_{i=1}\sigma_i^2}}
$$
### McNemar检验
|*算法B* | 算法A正确 | 算法A错误|
|---|---|---|
|**正确** | e00 | e01|
|**错误** | e10 | e11|
$$
\tau_{\chi^2} = \frac{(\vert e_{01}-e_{10} \vert -1)^2}{e_{01}+e_{10}}
$$
服从自由度为1的$\chi^2$分布，若小于临界值，则不能拒绝假设，没有显著差异。
### Friedman检验和Nemenyi后续检验
在一组数据集上对多个算法进行比较时，把数据集划分为多份，对每份进行各个算法的计算，并给各个算法进行排序，若两个算法排名相同，则平分序值（如2个人并列2,3名，则这两个人为2.5，第四名为4）。并对每个算法对应的每一个数据集计算平均序值。

令$r_i$为第i个算法的平均序值，则$r_i$的均值和方差分别为$(k+1)/2$和$(k^2-1)/12$。在k和N较大时，变量$\tau_{\chi^2}$服从自由度为$k-1$的$\chi^2$分布。
$$
\tau_{\chi^2} = \frac{k-1}{k}\cdot\frac{12N}{k^2-1}\sum^k_{i=1}(r_i-\frac{k+1}{2})^2

= \frac{12N}{k(k+1)}(\sum^k_{i=1}r_i^2-\frac{k(k+1)^2}{4})
$$
但是它要求k>30，过于保守，故往往用下式：
$$
\tau_{F^2} = \frac{(N-1)\tau_{\chi^2}}{N(k-1)-\tau_{\chi^2}}
$$
，服从自由度为k-1和(k-1)(N-1)的F分布。

若是假设被拒绝，说明有显著区别，就要用Nemenyi后续检验，计算出平均须知差别的临界值域($q_\alpha$可查表)：
$$
CD = q_\alpha\sqrt{\frac{k(k+1)}{6N}}
$$
对于每一个算法，对每一个数据集求CD并画图。若两个算法有交叠，则无明显区别，若一个算法明显比另一个前，则该算法更佳。















## 硬间隔
把正例和反例通过一个超平面划分：
$$
w^Tx+b=0
$$
那么此时样本空间中的点x到超平面(w,b)的距离为：
$$
r = \frac{|w^Tx+b|}{||w||}
$$
因此两个异类到超平面的硬间距margin为：
$$
r = \frac{2}{||w||}
$$
（因为必定存在放缩，使得$w^Tx_i+b \geq \pm 1$，即间距大于等于1）。
此时问题变为求：
$$
\max_{w,b} \frac{2}{||w||} , s.t.\ \ y_i(w^Tx_i+b) \geq 1 \\

\text{即} \min_{w,b} \frac{1}{2}||w|| , s.t.\ \ y_i(w^Tx_i+b) \geq 1
$$
此时，用KKT条件下的拉格朗日乘子法：
$$
\max_{\alpha \geq 0} L(w,b,\alpha) = \frac{1}{2}||w||^2 + \sum_{i=1}^m \alpha_i (1-y_i(w^Tx_i+b))
$$
(核心在这个公式，如果非支持向量，后面$(1-y_i(w^Tx_i+b))>0$为了满足最大化，$\alpha_i$必须=0，所以不会对模型造成影响，所以叫支持向量机。）对w,b求偏导 = 0：
$$
w = \sum_{i=1}^m \alpha_i y_i x_i \text{  （代入上式）}\\

0 = \sum_{i=1}^m \alpha_i y_i\\

=> \max_\alpha \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i=1}^m \sum_{i=1}^m \alpha_i \alpha_j y_i y_j x_i^T x_j ,\ \  
s.t. \sum_{i=1}^m \alpha_i y_i = 0 \\

\text{## 其中约束可以重写为：}\alpha_i y_i + \alpha_j y_j = -\sum_{k\ne i,j} \alpha_k y_k \\

\text{此时固定} \alpha_j,\alpha_i,\text{之外的变量，并将此约束代回求max的式中进行求解。}
$$

此时$\alpha_i$为要更新的权重，那么对其用SMO算法可得。


## 核函数
由于线性划分不一定能完全划分，需要$\phi(x)$映射到高维，但显然会加大计算量。
因此根据求max式，若有$k(x_i,x_j) = \phi(x_i)^T \phi(x_j)$，那么即可降低复杂度。
$$
\text{求解完成后，将}w^T = \sum_{i=1}^m \alpha_i y_i x_i^T \text{代回}f(x)=w^T\phi(x)+b \\

\text{得到}=\sum_{i=1}^m \alpha_iy_i k(x,x_i) + b
$$
- 线性核： $k(x_i,x_j) = x_i^Tx_j$
- 多项式核： $k(x_i,x_j) = (x_i^Tx_j)^d$，其中d≥1为多项式的次数
- 高斯核： $k(x_i,x_j) = exp(-\frac{||x_i-x_j||^2}{2\sigma^2})$，其中σ>0为高斯核的贷款
- 拉普拉斯核： $k(x_i,x_j) = x_i^Tx_j$，σ>0
- Sigmoid核： $k(x_i,x_j) = tanh(\beta x_i^T x_j + \theta)$，其中β>0，θ<0

## 软间隔

目标问题添加松弛：
$$
y_i(w^Tx_i+b)\geq 1-\xi_i \\
\min \frac{1}{2}||w||^2 + C\sum_{i=1}^n \xi_i \\
s.t. \ \ \ y_i(w^T+b)\geq 1-\xi_i \ , \ \xi_i\geq0
$$

其中，$\xi_i$控制对每个样本的容忍程度，C控制“间距尽量小”和“有噪声情况下的容忍：数据点偏差量最小”两个问题的权重。

同理，拉格朗日：

$$
L(w,b,\xi,\alpha,r) = \frac{1}{2}||w||^2+C\sum_{i=1}^n\xi_i-\sum_{i=1}^n \alpha_i (y_i(w^Tx_i+b)-1+\xi_i) - \sum_{i=1}^n r_i\xi_i
$$

同理，对$w,b,\xi_i$求偏导=0，并代回
$$
w = \sum_{i=1}^n \alpha_iy_ix_i \\
\sum_{i=1}^n \alpha_iy_y = 0 \\
C-\alpha_i-r_i=0 \\
$$
=> 代入，因为存在第三条，所以$C$和$\alpha_i$也存在关系，要另加约束 $0 \leq\alpha_i \leq C$
$$
\max_\alpha \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i=1}^m \sum_{i=1}^m \alpha_i \alpha_j y_i y_j x_i^T x_j ,\ \  \\
s.t. \sum_{i=1}^m \alpha_i y_i = 0 , 0 \leq\alpha_i \leq C \\
$$

最后使用SMO求解



## SMO

目标问题：
$$
y_i(w^Tx_i+b)\geq 1-\xi_i \\
\min \frac{1}{2}||w||^2 + C\sum_{i=1}^n \xi_i \\
s.t. \ \ \ y_i(w^T+b)\geq 1-\xi_i \ , \ \xi_i\geq 0 \\
L(w,b,\xi,\alpha,r) = \frac{1}{2}||w||^2+C\sum_{i=1}^n\xi_i-\sum_{i=1}^n \alpha_i (y_i(w^Tx_i+b)-1+\xi_i) - \sum_{i=1}^n r_i\xi_i
$$

$$
\max_\alpha \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i=1}^m \sum_{i=1}^m \alpha_i \alpha_j y_i y_j x_i^T x_j ,\ \  \\
s.t. \sum_{i=1}^m \alpha_i y_i = 0 , 0 \leq\alpha_i \leq C \\
$$


对于上面这个问题，可以等价于
$$
\min_\alpha \frac{1}{2}\sum_{i=1}^m \sum_{i=1}^m \alpha_i \alpha_j y_i y_j K(x_i,x_j） - \sum_{i=1}^m \alpha_i\ , \\
s.t. \sum_{i=1}^m \alpha_i y_i = 0 , 0 \leq\alpha_i \leq C \\
$$
SMO对于线性SVM和数据稀疏时很快。每次选取两个乘子$\alpha_1$和$\alpha_2$作为变量，其他作为常量，去迭代更新。表达如下：
$$
原式=\frac{1}{2}K_{11}\alpha_1^2 + \frac{1}{2}K_{22}\alpha_2^2 + sK_{12}\alpha_1\alpha_2+y_1\alpha_1v_1+y_2\alpha_2v_2-\alpha_1-\alpha_2+constant \\
其中，s = 1 \text{ if } (y_i==y_j) \text{ else } -1 \\
K_{i,j}=K(x_i,x_j),\\
v_i = \sum_{j=1}^n y_i\alpha_j^*K_{ij} = w-y_1\alpha_1^*K_{1i}-y_2\alpha_2^*K_{2i}
$$
要满足三种情况的条件：

- 点在边界内部，则$\alpha_i = 0  \Longleftrightarrow y_i u_i \geq 1 $
- 点是支持向量，在边界上，则$0<\alpha_i<C \Longleftrightarrow y_i u_i=1$
- 点在两条边界之间，$\alpha_i=C \Longleftrightarrow y_i u_i \leq  1$

因此比如$\alpha_i<C $ 且 $ y_i u_i \leq  1$，则不满足条件。凡是不满足的，应该对$\alpha$更新（这是第一个约束）。

对另一个约束，只要确保$\alpha_1y_1+\alpha_2y_2$变动前后相等，且等于同一常量。

因此综合这两个约束，先求一个乘子，再求另一个，迭代求解。



选取$\alpha_1$,$\alpha_2$的规则：

1. 选取第一个违反KKT条件的作为$\alpha_2$优先更新。
2. 选取不违反条件中，找到使变动前后可以提升最多的作为$\alpha_1$进行更新。



























